{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe776a62-6003-4e5f-bac8-9cfc6f3e9c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3309500",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m## For plotting\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m rcParams\n\u001b[1;32m      8\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmatplotlib\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minline\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "## Common python packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "## For plotting\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set_style(\"white\")\n",
    "sns.set_context(\"notebook\")\n",
    "sns.set_color_codes()\n",
    "\n",
    "## sklearn - ML tools\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay, roc_curve, auc, precision_recall_curve\n",
    "from sklearn.utils import resample, shuffle\n",
    "\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "## weighted stats\n",
    "from statsmodels.stats.weightstats import DescrStatsW\n",
    "\n",
    "## \"-\" sign for graphs\n",
    "rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "## Some extra styling\n",
    "def namestr(obj, namespace = globals()):\n",
    "    \"Prints the name of a variable\"\n",
    "    return [name for name in namespace if namespace[name] is obj][0]\n",
    "\n",
    "## For time\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "## For country encoding\n",
    "from dataprep.clean import clean_country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d97118",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Univar Tools\n",
    "def data_stats(df, cols = None):\n",
    "    cols = df.columns if cols is None else cols\n",
    "    return pd.DataFrame({\"Mean\": df[cols].mean, \"Med\": df[cols].median(), \"STD\": df[cols].std, \n",
    "                         \"Min\": df[cols].min(), \"Max\": df[cols].max()})\n",
    "              \n",
    "def hist_plotter(df, cols = None, range_x = None, n_std = 1, size = None, nbin = 100):\n",
    "    cols = df.select_dtypes(include=np.number).columns if cols is None else cols\n",
    "    for col in cols:\n",
    "        range_ = [df[col].min() + n_std * df[col].std(), df[col].max() - n_std * df[col].std()] if range_x is None else range_x\n",
    "        fig, ax = plt.subplots(1,1)\n",
    "        df[col].plot(kind = \"hist\", range = range_, edgecolor = \"blue\", alpha = 1, bins = nbin, density = 1, ax = ax, figsize = size)\n",
    "        plt.xlabel(col)\n",
    "        plt.show()\n",
    "    \n",
    "def box_plotter(df, cols = None):\n",
    "    cols = df.columns if cols is None else cols\n",
    "    fig, ax = plt.subplots(1, 1)\n",
    "    df[cols].boxplot(ax=ax)\n",
    "    plt.xticks(rotation = 90)\n",
    "    plt.show()\n",
    "    \n",
    "## Bivar Tools\n",
    "def data_corr(df, size = None, cols = None):\n",
    "    cols = df.columns if cols is None else cols \n",
    "    size = (len(cols), len(cols)) if size is None else size\n",
    "    plt.figure(figsize = size)\n",
    "    sns.heatmap(df.corr(), cmap = \"coolwarm\", square = True, vmin = -1, vmax = 1, annot=True)\n",
    "    plt.show()\n",
    "        \n",
    "## For date conversion\n",
    "month_lib = {\n",
    "    \"jan\": 0,\n",
    "    \"feb\": 1,    \n",
    "    \"mar\": 2,\n",
    "    \"apr\": 3,    \n",
    "    \"may\": 4,\n",
    "    \"jun\": 5,    \n",
    "    \"jul\": 6,\n",
    "    \"aug\": 7,    \n",
    "    \"sep\": 8,\n",
    "    \"oct\": 9,    \n",
    "    \"nov\": 10,\n",
    "    \"dec\": 11\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0dc0830",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"datasets_hi4/train-data.csv\", sep=\";\")\n",
    "\n",
    "date = df[\"Date\"].str.split(n=1, expand=True)\n",
    "df[\"Year\"] = date[1]\n",
    "df[\"Trisem\"] = pd.to_numeric(date[0].str.slice(stop=3).replace(month_lib))//3\n",
    "df[\"Trisem\"] = df[\"Trisem\"].astype(str)\n",
    "\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "for col in [\"Month 1\", \"Month 2\", \"Month 3\", \"Month 4\"]:\n",
    "    df[col] = pd.to_numeric(df[col].str.replace(\" \", \"\"))\n",
    "       \n",
    "#df['Month 1'] = df.groupby('Strategic Product Family proxy')['Month 1'].transform(lambda x: x.fillna(x.mean()))\n",
    "df[\"Product Life cycel status\"] = df[\"Product Life cycel status\"].fillna(\"ACT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4bbc6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_GSCPI = pd.read_csv(\"datasets_hi4/extra-dataset/GSCPI_data.csv\")\n",
    "\n",
    "df_GSCPI[\"Year\"] = df_GSCPI[\"Year-Month\"].str.slice(stop=4)\n",
    "df_GSCPI[\"Trisem\"] = pd.to_numeric(df_GSCPI[\"Year-Month\"].str.slice(start=5))//3\n",
    "df_GSCPI[\"Trisem\"] = df_GSCPI[\"Trisem\"].astype(str)\n",
    "\n",
    "df_GSCPI = df_GSCPI.groupby([\"Year\", \"Trisem\"], as_index=False)[\"GSCPI\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646c43e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_LPI = pd.read_csv(\"datasets_hi4/extra-dataset/LPIextend.csv\")\n",
    "\n",
    "cols = []\n",
    "for col in df_LPI.columns:\n",
    "    if \"Score\" in col:\n",
    "            cols.append(col)\n",
    "            \n",
    "df_LPI[\"LogPerf\"] = df_LPI[cols].mean(axis=1)\n",
    "df_LPI = df_LPI.replace('TC<rkiye',\"Turkey\")\n",
    "df_LPI = clean_country(df_LPI, \"Country\", output_format=\"alpha-2\", inplace=True)\n",
    "df_LPI[\"Country_clean\"] = df_LPI[\"Country_clean\"].fillna('NA')\n",
    "\n",
    "df_LPI = df_LPI[[\"Country_clean\", \"LogPerf\"]].rename(columns={\"Country_clean\": \"Country\"}) \n",
    "df_LPI[\"LogPerf\"] = df_LPI[\"LogPerf\"].transform(lambda x: x.fillna(x.mean() - (1/5) * x.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0924718c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inf = pd.read_csv(\"datasets_hi4/extra-dataset/worldbank_inflation_data.csv\")\n",
    "\n",
    "inf_years = np.array(list(map(lambda x: x.split('-')[0], df_inf[\"Year-Month\"].to_list())))\n",
    "inf_months = np.array(list(map(lambda x: int(x.split('-')[1]), df_inf[\"Year-Month\"].to_list())))\n",
    "\n",
    "df_inf[\"Year\"] = inf_years\n",
    "df_inf[\"Trisem\"] = list(map(str, (inf_months - 1)//4))\n",
    "\n",
    "df_inf = df_inf.replace('SÃ£o TomÃ© and Principe',\"Sao Tome and Principe\")\n",
    "df_inf = clean_country(df_inf, \"Country\", output_format=\"alpha-2\")\n",
    "df_inf.drop(columns = ['Country', 'Year-Month'], inplace = True)\n",
    "df_inf.rename(columns = {\"Country_clean\": \"Country\"}, inplace = True)\n",
    "df_inf[\"Country\"] = df_inf[\"Country\"].fillna('NA')\n",
    "\n",
    "df_inf[\"Energy Price Index\"] = df_inf[\"Energy Price Index\"].transform(lambda x: x.fillna(x.mean()))\n",
    "df_inf[\"Headline Consumer Price Index\"] = df_inf[\"Headline Consumer Price Index\"].transform(lambda x: x.fillna(x.mean()))\n",
    "\n",
    "dfi_grouped = df_inf.groupby([\"Year\", \"Trisem\", \"Country\"])[\"Energy Price Index\", \"Headline Consumer Price Index\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e8da07",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_epi = pd.read_csv(\"datasets_hi4/extra-dataset/epi2022results05302022.csv\")\n",
    "\n",
    "df_epi = clean_country(df_epi, \"country\", output_format=\"alpha-2\", inplace=True)\n",
    "df_epi = df_epi[[\"country_clean\", \"SDA.new\", \"NXA.new\", \"CDA.new\", \"CHA.new\", \"NDA.new\",\n",
    "                 \"BCA.new\", \"GIB.new\", \"GHP.new\"]]\n",
    "df_epi = df_epi.rename(columns = {\"country_clean\": \"Country\"})\n",
    "df_epi[\"EmAv\"] = df_epi[[\"NXA.new\", \"CDA.new\", \"SDA.new\", \"BCA.new\", \"NDA.new\"]].mean(axis=1)\n",
    "df_epi = df_epi.drop([\"NXA.new\",\"CDA.new\",\"SDA.new\",\"BCA.new\",\"NDA.new\"],axis=1)\n",
    "\n",
    "df_epi[\"Country\"] = df_epi[\"Country\"].fillna('NA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f563e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_econ = pd.read_csv(\"datasets_hi4/extra-dataset/worldbank_economic_data.csv\")\n",
    "\n",
    "df_econ = df_econ[df_econ[\"Country\"].str.contains(\"Macao\")==False ]\n",
    "\n",
    "df_econ = df_econ.replace('Turkiye',\"Turkey\")\n",
    "df_econ = clean_country(df_econ, \"Country\", output_format=\"alpha-2\")\n",
    "df_econ = df_econ.dropna(subset = \"Country_clean\")\n",
    "df_econ.drop(columns = ['Country'], inplace = True)\n",
    "df_econ.rename(columns = {\"Country_clean\": \"Country\"}, inplace = True)\n",
    "\n",
    "df_econ[\"Year\"] = df_econ[\"Year\"].astype(str)\n",
    "\n",
    "df_econ = df_econ[['Country', \"Year\", \n",
    "                   'Final consumption expenditure (annual % growth)', \n",
    "                   'GDP (current US$)', \n",
    "                   'Imports of goods and services (annual % growth)']].drop_duplicates()\n",
    "\n",
    "df_econ[\"Final consumption expenditure (annual % growth)\"] = df_econ[\"Final consumption expenditure (annual % growth)\"].transform(lambda x: x.fillna(x.mean()))\n",
    "df_econ[\"Imports of goods and services (annual % growth)\"] = df_econ[\"Imports of goods and services (annual % growth)\"].transform(lambda x: x.fillna(x.mean()))\n",
    "df_econ[\"GDP (current US$)\"] = df_econ[\"GDP (current US$)\"].transform(lambda x: x.fillna(x.mean()))\n",
    "\n",
    "TW_rows = pd.DataFrame([[\"TW\", str(2020 + i), \n",
    "                         df_econ[\"Final consumption expenditure (annual % growth)\"].mean(), \n",
    "                         df_econ[\"GDP (current US$)\"].mean(),\n",
    "                         df_econ[\"Imports of goods and services (annual % growth)\"].mean()] for i in range(4)], \n",
    "                       columns = df_econ.columns)\n",
    "\n",
    "df_econ = df_econ.append(TW_rows, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffeba7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mdf = pd.merge(df, df_GSCPI, on=[\"Year\", \"Trisem\"])\n",
    "mdf = pd.merge(mdf, df_LPI, on =[\"Country\"])\n",
    "mdf = pd.merge(mdf, df_epi, on=[\"Country\"])\n",
    "mdf = pd.merge(mdf, df_econ, on = ['Country', 'Year'])\n",
    "mdf_train = pd.merge(mdf, dfi_grouped, how = \"left\", on = [\"Year\", \"Trisem\", \"Country\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "ab6e6260",
   "metadata": {},
   "outputs": [],
   "source": [
    "mdf_train = pd.read_csv(\"datasets_hi4/out.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "bbe7b6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataX, datay = mdf_train.drop(columns = [\"Month 4\"]), mdf_train[\"Month 4\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataX, datay, test_size = .2, random_state=42)\n",
    "X_train['Month 1'] = X_train.groupby('Strategic Product Family proxy')['Month 1'].transform(lambda x: x.fillna(x.mean()))\n",
    "X_test['Month 1'] = X_test.groupby('Strategic Product Family proxy')['Month 1'].transform(lambda x: x.fillna(x.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd0ec5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "74bd0190",
   "metadata": {},
   "source": [
    "# Encoding and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "217aa0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "from tensorflow.keras.layers import CategoryEncoding, StringLookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "0c24dd16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "d24bc2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_clone = X_train.copy(deep = True)\n",
    "X_test_clone = X_test.copy(deep = True)\n",
    "y_train_clone = y_train.copy(deep = True)\n",
    "y_test_clone = y_test.copy(deep = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "c2069ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "irrelevant_features = [ \n",
    "                         \"Strategic Product Family proxy\",\n",
    "                         \"Operations\",\n",
    "#                         \"Zone\",\n",
    "#                         \"Cluster\",\n",
    "#                         \"Reference proxy\",\n",
    "                         \"Site\",\n",
    "                         \"Country\",\n",
    "#                         \"Division proxy\",\n",
    "#                         \"Customer Persona proxy\",\n",
    "                         \"Date\",\n",
    "                         'Energy Price Index',\n",
    "                         'Headline Consumer Price Index'\n",
    "]\n",
    "\n",
    "X_train.drop(columns = irrelevant_features, inplace = True)\n",
    "X_test.drop(columns = irrelevant_features, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "7bccc47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[\"Year\"] = X_train[\"Year\"].astype(int)\n",
    "X_train[\"Trisem\"] = X_train[\"Trisem\"].astype(int)\n",
    "\n",
    "X_test[\"Year\"] = X_test[\"Year\"].astype(int)\n",
    "X_test[\"Trisem\"] = X_test[\"Trisem\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "8006271c",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols_string = ['Region', 'Product Life cycel status', 'Product  Line proxy', \n",
    "                          \"Zone\", \"Cluster\", \"Reference proxy\", \"Division proxy\", \"Customer Persona proxy\"]\n",
    "categorical_cols_int = ['index', 'id_product', 'Year', \"Trisem\"]\n",
    "numerical_cols = list(set(X_train.columns) - set(categorical_cols_string) - set(categorical_cols_int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "6096a9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, \n",
    "                                                    test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "6d387e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_dataset(dataframe_X, dataframe_y, shuffle=True, batch_size=32):\n",
    "    df_X = dataframe_X.copy()\n",
    "    df_y = dataframe_y.copy()\n",
    "    labels = df_y\n",
    "    df = {key: value[:,tf.newaxis] for key, value in dataframe_X.items()}\n",
    "    ds = tf.data.Dataset.from_tensor_slices((dict(df), labels))\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(buffer_size=len(dataframe_X))\n",
    "    ds = ds.batch(batch_size)\n",
    "    ds = ds.prefetch(batch_size)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "6fdbf222",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in X_test.columns:\n",
    "    if column in numerical_cols: \n",
    "        X_test[column] = np.asarray(X_test[column]).astype('float32')\n",
    "        X_train[column] = np.asarray(X_train[column]).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "1a3028ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_normalization_layer(name, dataset):\n",
    "    # Create a Normalization layer for the feature.\n",
    "    normalizer = layers.Normalization(axis=None)\n",
    "  \n",
    "    # Prepare a Dataset that only yields the feature.\n",
    "    feature_ds = dataset.map(lambda x, y: x[name])\n",
    "  \n",
    "    # Learn the statistics of the data.\n",
    "    normalizer.adapt(feature_ds)\n",
    "  \n",
    "    return normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "93ac3941",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_category_encoding_layer(name, dataset, dtype, max_tokens=None):\n",
    "    # Create a layer that turns strings into integer indices.\n",
    "    if dtype == 'string':\n",
    "        index = layers.StringLookup(max_tokens=max_tokens)\n",
    "    # Otherwise, create a layer that turns integer values into integer indices.\n",
    "    else:\n",
    "        index = layers.IntegerLookup(max_tokens=max_tokens)\n",
    "  \n",
    "    # Prepare a `tf.data.Dataset` that only yields the feature.\n",
    "    feature_ds = dataset.map(lambda x, y: x[name])\n",
    "  \n",
    "    # Learn the set of possible values and assign them a fixed integer index.\n",
    "    index.adapt(feature_ds)\n",
    "  \n",
    "    # Encode the integer indices.\n",
    "    encoder = layers.CategoryEncoding(num_tokens=index.vocabulary_size())\n",
    "  \n",
    "    # Apply multi-hot encoding to the indices. The lambda function captures the\n",
    "    # layer, so you can use them, or include them in the Keras Functional model later.\n",
    "    return lambda feature: encoder(index(feature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "037bac1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_291702/2449884235.py:5: FutureWarning: Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n",
      "  df = {key: value[:,tf.newaxis] for key, value in dataframe_X.items()}\n",
      "/tmp/ipykernel_291702/2449884235.py:5: FutureWarning: Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n",
      "  df = {key: value[:,tf.newaxis] for key, value in dataframe_X.items()}\n",
      "/tmp/ipykernel_291702/2449884235.py:5: FutureWarning: Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n",
      "  df = {key: value[:,tf.newaxis] for key, value in dataframe_X.items()}\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1024\n",
    "train_ds = df_to_dataset(X_train, y_train, batch_size=batch_size)\n",
    "val_ds = df_to_dataset(X_val, y_val, shuffle=False, batch_size=batch_size)\n",
    "test_ds = df_to_dataset(X_test, y_test, shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "875ae262",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-03 09:11:40.615981: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_6' with dtype float and shape [1363338,1]\n",
      "\t [[{{node Placeholder/_6}}]]\n",
      "2023-12-03 09:11:40.616420: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_4' with dtype float and shape [1363338,1]\n",
      "\t [[{{node Placeholder/_4}}]]\n",
      "2023-12-03 09:11:56.419294: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_4' with dtype float and shape [1363338,1]\n",
      "\t [[{{node Placeholder/_4}}]]\n",
      "2023-12-03 09:11:56.419724: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_7' with dtype float and shape [1363338,1]\n",
      "\t [[{{node Placeholder/_7}}]]\n",
      "2023-12-03 09:12:12.104039: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype float and shape [1363338,1]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-12-03 09:12:12.104466: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_11' with dtype float and shape [1363338,1]\n",
      "\t [[{{node Placeholder/_11}}]]\n",
      "2023-12-03 09:12:27.817425: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_9' with dtype float and shape [1363338,1]\n",
      "\t [[{{node Placeholder/_9}}]]\n",
      "2023-12-03 09:12:27.817854: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_5' with dtype float and shape [1363338,1]\n",
      "\t [[{{node Placeholder/_5}}]]\n",
      "2023-12-03 09:12:43.507893: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_5' with dtype float and shape [1363338,1]\n",
      "\t [[{{node Placeholder/_5}}]]\n",
      "2023-12-03 09:12:43.508327: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype string and shape [1363338,1]\n",
      "\t [[{{node Placeholder/_1}}]]\n",
      "2023-12-03 09:12:59.188132: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype float and shape [1363338,1]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-12-03 09:12:59.188554: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_8' with dtype float and shape [1363338,1]\n",
      "\t [[{{node Placeholder/_8}}]]\n",
      "2023-12-03 09:13:14.887726: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_17' with dtype string and shape [1363338,1]\n",
      "\t [[{{node Placeholder/_17}}]]\n",
      "2023-12-03 09:13:14.888145: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_8' with dtype float and shape [1363338,1]\n",
      "\t [[{{node Placeholder/_8}}]]\n",
      "2023-12-03 09:13:31.089713: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_9' with dtype float and shape [1363338,1]\n",
      "\t [[{{node Placeholder/_9}}]]\n",
      "2023-12-03 09:13:31.090139: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_8' with dtype float and shape [1363338,1]\n",
      "\t [[{{node Placeholder/_8}}]]\n",
      "2023-12-03 09:13:46.823798: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_17' with dtype string and shape [1363338,1]\n",
      "\t [[{{node Placeholder/_17}}]]\n",
      "2023-12-03 09:13:46.824230: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_7' with dtype float and shape [1363338,1]\n",
      "\t [[{{node Placeholder/_7}}]]\n",
      "2023-12-03 09:14:02.590012: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_9' with dtype float and shape [1363338,1]\n",
      "\t [[{{node Placeholder/_9}}]]\n",
      "2023-12-03 09:14:02.590458: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_25' with dtype int64 and shape [1363338]\n",
      "\t [[{{node Placeholder/_25}}]]\n",
      "2023-12-03 09:14:18.285969: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_8' with dtype float and shape [1363338,1]\n",
      "\t [[{{node Placeholder/_8}}]]\n",
      "2023-12-03 09:14:18.286435: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_5' with dtype float and shape [1363338,1]\n",
      "\t [[{{node Placeholder/_5}}]]\n",
      "2023-12-03 09:14:33.958551: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_22' with dtype string and shape [1363338,1]\n",
      "\t [[{{node Placeholder/_22}}]]\n",
      "2023-12-03 09:14:33.958978: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_12' with dtype float and shape [1363338,1]\n",
      "\t [[{{node Placeholder/_12}}]]\n",
      "2023-12-03 09:14:49.705641: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_15' with dtype string and shape [1363338,1]\n",
      "\t [[{{node Placeholder/_15}}]]\n",
      "2023-12-03 09:14:49.706062: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype float and shape [1363338,1]\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    }
   ],
   "source": [
    "all_inputs = []\n",
    "encoded_features = []\n",
    "\n",
    "# Numerical features.\n",
    "for header in numerical_cols:\n",
    "    numeric_col = tf.keras.Input(shape=(1,), name=header)\n",
    "    normalization_layer = get_normalization_layer(header, train_ds)\n",
    "    encoded_numeric_col = normalization_layer(numeric_col)\n",
    "    all_inputs.append(numeric_col)\n",
    "    encoded_features.append(encoded_numeric_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "be36fd79",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-03 09:15:05.954842: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_8' with dtype float and shape [1363338,1]\n",
      "\t [[{{node Placeholder/_8}}]]\n",
      "2023-12-03 09:15:05.955260: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_22' with dtype string and shape [1363338,1]\n",
      "\t [[{{node Placeholder/_22}}]]\n",
      "2023-12-03 09:15:21.643074: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_9' with dtype float and shape [1363338,1]\n",
      "\t [[{{node Placeholder/_9}}]]\n",
      "2023-12-03 09:15:21.643490: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_11' with dtype float and shape [1363338,1]\n",
      "\t [[{{node Placeholder/_11}}]]\n",
      "2023-12-03 09:15:37.288031: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_24' with dtype int64 and shape [1363338,1]\n",
      "\t [[{{node Placeholder/_24}}]]\n",
      "2023-12-03 09:15:37.288459: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_8' with dtype float and shape [1363338,1]\n",
      "\t [[{{node Placeholder/_8}}]]\n",
      "2023-12-03 09:15:52.883774: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_5' with dtype float and shape [1363338,1]\n",
      "\t [[{{node Placeholder/_5}}]]\n",
      "2023-12-03 09:15:52.884205: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_6' with dtype float and shape [1363338,1]\n",
      "\t [[{{node Placeholder/_6}}]]\n",
      "2023-12-03 09:16:08.533258: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_11' with dtype float and shape [1363338,1]\n",
      "\t [[{{node Placeholder/_11}}]]\n",
      "2023-12-03 09:16:08.533684: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_9' with dtype float and shape [1363338,1]\n",
      "\t [[{{node Placeholder/_9}}]]\n",
      "2023-12-03 09:16:24.189538: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_20' with dtype float and shape [1363338,1]\n",
      "\t [[{{node Placeholder/_20}}]]\n",
      "2023-12-03 09:16:24.189964: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_3' with dtype string and shape [1363338,1]\n",
      "\t [[{{node Placeholder/_3}}]]\n",
      "2023-12-03 09:16:42.997931: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_9' with dtype float and shape [1363338,1]\n",
      "\t [[{{node Placeholder/_9}}]]\n",
      "2023-12-03 09:16:42.999433: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_9' with dtype float and shape [1363338,1]\n",
      "\t [[{{node Placeholder/_9}}]]\n",
      "2023-12-03 09:16:53.108712: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:392] Filling up shuffle buffer (this may take a while): 1315437 of 1363338\n",
      "2023-12-03 09:16:53.630663: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:417] Shuffle buffer filled.\n",
      "2023-12-03 09:17:06.849119: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_4' with dtype float and shape [1363338,1]\n",
      "\t [[{{node Placeholder/_4}}]]\n",
      "2023-12-03 09:17:06.851275: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_6' with dtype float and shape [1363338,1]\n",
      "\t [[{{node Placeholder/_6}}]]\n"
     ]
    }
   ],
   "source": [
    "for header in categorical_cols_string:\n",
    "    categorical_col = tf.keras.Input(shape=(1,), name=header, dtype='string')\n",
    "    encoding_layer = get_category_encoding_layer(name=header,\n",
    "                                                 dataset=train_ds,\n",
    "                                                 dtype='string',\n",
    "                                                 max_tokens=5)\n",
    "    encoded_categorical_col = encoding_layer(categorical_col)\n",
    "    all_inputs.append(categorical_col)\n",
    "    encoded_features.append(encoded_categorical_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "964dd61b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-03 09:17:25.879070: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_20' with dtype float and shape [1363338,1]\n",
      "\t [[{{node Placeholder/_20}}]]\n",
      "2023-12-03 09:17:25.881377: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_5' with dtype float and shape [1363338,1]\n",
      "\t [[{{node Placeholder/_5}}]]\n",
      "2023-12-03 09:17:43.890633: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_8' with dtype float and shape [1363338,1]\n",
      "\t [[{{node Placeholder/_8}}]]\n",
      "2023-12-03 09:17:43.891080: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_4' with dtype float and shape [1363338,1]\n",
      "\t [[{{node Placeholder/_4}}]]\n",
      "2023-12-03 09:17:59.018236: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_25' with dtype int64 and shape [1363338]\n",
      "\t [[{{node Placeholder/_25}}]]\n",
      "2023-12-03 09:17:59.018663: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_6' with dtype float and shape [1363338,1]\n",
      "\t [[{{node Placeholder/_6}}]]\n",
      "2023-12-03 09:18:09.071036: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:392] Filling up shuffle buffer (this may take a while): 1042027 of 1363338\n",
      "2023-12-03 09:18:12.147211: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:417] Shuffle buffer filled.\n",
      "2023-12-03 09:18:20.598401: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_14' with dtype float and shape [1363338,1]\n",
      "\t [[{{node Placeholder/_14}}]]\n",
      "2023-12-03 09:18:20.598828: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_11' with dtype float and shape [1363338,1]\n",
      "\t [[{{node Placeholder/_11}}]]\n"
     ]
    }
   ],
   "source": [
    "for header in categorical_cols_int:\n",
    "    categorical_col = tf.keras.Input(shape=(1,), name=header, dtype='int64')\n",
    "    encoding_layer = get_category_encoding_layer(name=header,\n",
    "                                                 dataset=train_ds,\n",
    "                                                 dtype='int64',\n",
    "                                                 max_tokens=5)\n",
    "    encoded_categorical_col = encoding_layer(categorical_col)\n",
    "    all_inputs.append(categorical_col)\n",
    "    encoded_features.append(encoded_categorical_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce7a690",
   "metadata": {},
   "source": [
    "# Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "b9a8c9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = layers.concatenate(encoded_features)\n",
    "model = layers.Dense(32, activation='tanh')(all_features)\n",
    "model = layers.BatchNormalization()(model)\n",
    "model = layers.Dense(64, activation='tanh')(model)\n",
    "#model = layers.BatchNormalization()(model)\n",
    "model = layers.Dense(128, activation='tanh')(model)\n",
    "#model = layers.BatchNormalization()(model)\n",
    "model = layers.Dense(64, activation='tanh')(model)\n",
    "#model = layers.BatchNormalization()(model)\n",
    "model = layers.Dense(32, activation='tanh')(model)\n",
    "model = layers.BatchNormalization()(model)\n",
    "output = layers.Dense(1, activation='relu')(model)\n",
    "\n",
    "final_model = tf.keras.Model(all_inputs, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "19eab052",
   "metadata": {},
   "outputs": [],
   "source": [
    "init_lr = 10**(-2.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "64a4b930",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model.compile(optimizer=keras.optimizers.Adam(learning_rate=init_lr),\n",
    "              loss=tf.keras.losses.MeanSquaredError(reduction=\"sum_over_batch_size\", name=\"mean_squared_error\"),\n",
    "              metrics=[keras.metrics.RootMeanSquaredError(name=\"root_mean_squared_error\", dtype=None)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "5475fee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "# Use `rankdir='LR'` to make the graph horizontal.\n",
    "tf.keras.utils.plot_model(final_model, show_shapes=True, rankdir=\"LR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "d0f513b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-03 11:08:46.568881: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype float and shape [1363338,1]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-12-03 11:08:46.569332: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_5' with dtype float and shape [1363338,1]\n",
      "\t [[{{node Placeholder/_5}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1328/1332 [============================>.] - ETA: 0s - loss: 637962.0625 - root_mean_squared_error: 798.7253"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-03 11:09:05.821092: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_6' with dtype double and shape [151482,1]\n",
      "\t [[{{node Placeholder/_6}}]]\n",
      "2023-12-03 11:09:05.821936: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_6' with dtype double and shape [151482,1]\n",
      "\t [[{{node Placeholder/_6}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1332/1332 [==============================] - 21s 9ms/step - loss: 636871.0625 - root_mean_squared_error: 798.0420 - val_loss: 426705.5938 - val_root_mean_squared_error: 653.2271\n",
      "Epoch 2/6\n",
      "1332/1332 [==============================] - 20s 10ms/step - loss: 545369.3750 - root_mean_squared_error: 738.4913 - val_loss: 349670.2812 - val_root_mean_squared_error: 591.3292\n",
      "Epoch 3/6\n",
      "1332/1332 [==============================] - 18s 9ms/step - loss: 506921.9062 - root_mean_squared_error: 711.9845 - val_loss: 328856.6250 - val_root_mean_squared_error: 573.4602\n",
      "Epoch 4/6\n",
      "1332/1332 [==============================] - 19s 9ms/step - loss: 479143.1250 - root_mean_squared_error: 692.2017 - val_loss: 554870.3125 - val_root_mean_squared_error: 744.8962\n",
      "Epoch 5/6\n",
      "1332/1332 [==============================] - 18s 9ms/step - loss: 467963.8438 - root_mean_squared_error: 684.0789 - val_loss: 321313.7812 - val_root_mean_squared_error: 566.8455\n",
      "Epoch 6/6\n",
      "1332/1332 [==============================] - 19s 9ms/step - loss: 457502.2812 - root_mean_squared_error: 676.3892 - val_loss: 289624.6250 - val_root_mean_squared_error: 538.1678\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0e524a6b50>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model.fit(train_ds, epochs=6, validation_data=val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "0ef55e82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-03 11:10:47.748398: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype string and shape [378706,1]\n",
      "\t [[{{node Placeholder/_2}}]]\n",
      "2023-12-03 11:10:47.748826: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_13' with dtype float and shape [378706,1]\n",
      "\t [[{{node Placeholder/_13}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "370/370 [==============================] - 4s 9ms/step - loss: 508729.9062 - root_mean_squared_error: 713.2531\n",
      "Accuracy 713.2530517578125\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = final_model.evaluate(test_ds)\n",
    "print(\"Accuracy\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0f9107-3ebb-4a8c-8a62-a0f8b6f47af2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "7755a4b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Month 1\n",
      "Month 2\n",
      "LogPerf\n",
      "GHP.new\n",
      "GDP (current US$)\n",
      "GSCPI\n",
      "GIB.new\n",
      "Unnamed: 0\n",
      "Month 3\n",
      "Imports of goods and services (annual % growth)\n",
      "CHA.new\n",
      "EmAv\n",
      "Final consumption expenditure (annual % growth)\n",
      "Region\n",
      "Product Life cycel status\n",
      "Product  Line proxy\n",
      "Zone\n",
      "Cluster\n",
      "Reference proxy\n",
      "Division proxy\n",
      "Customer Persona proxy\n",
      "index\n",
      "id_product\n",
      "Year\n",
      "Trisem\n"
     ]
    }
   ],
   "source": [
    "columns = numerical_cols + categorical_cols_string + categorical_cols_int\n",
    "\n",
    "sample_key = {}\n",
    "for key in columns:\n",
    "    print(key)\n",
    "    sample_key[key] = tf.convert_to_tensor(X_train[key].values.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ecc153e4-bcbe-4e40-a9a3-452ccbd5ffc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " Region (InputLayer)            [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " Product Life cycel status (Inp  [(None, 1)]         0           []                               \n",
      " utLayer)                                                                                         \n",
      "                                                                                                  \n",
      " Product  Line proxy (InputLaye  [(None, 1)]         0           []                               \n",
      " r)                                                                                               \n",
      "                                                                                                  \n",
      " Zone (InputLayer)              [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " Cluster (InputLayer)           [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " Reference proxy (InputLayer)   [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " Division proxy (InputLayer)    [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " Customer Persona proxy (InputL  [(None, 1)]         0           []                               \n",
      " ayer)                                                                                            \n",
      "                                                                                                  \n",
      " index (InputLayer)             [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " id_product (InputLayer)        [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " Year (InputLayer)              [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " Trisem (InputLayer)            [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " Month 1 (InputLayer)           [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " Month 2 (InputLayer)           [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " LogPerf (InputLayer)           [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " GHP.new (InputLayer)           [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " GDP (current US$) (InputLayer)  [(None, 1)]         0           []                               \n",
      "                                                                                                  \n",
      " GSCPI (InputLayer)             [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " GIB.new (InputLayer)           [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " Unnamed: 0 (InputLayer)        [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " Month 3 (InputLayer)           [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " Imports of goods and services   [(None, 1)]         0           []                               \n",
      " (annual % growth) (InputLayer)                                                                   \n",
      "                                                                                                  \n",
      " CHA.new (InputLayer)           [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " EmAv (InputLayer)              [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " Final consumption expenditure   [(None, 1)]         0           []                               \n",
      " (annual % growth) (InputLayer)                                                                   \n",
      "                                                                                                  \n",
      " string_lookup (StringLookup)   (None, 1)            0           ['Region[0][0]']                 \n",
      "                                                                                                  \n",
      " string_lookup_1 (StringLookup)  (None, 1)           0           ['Product Life cycel status[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " string_lookup_2 (StringLookup)  (None, 1)           0           ['Product  Line proxy[0][0]']    \n",
      "                                                                                                  \n",
      " string_lookup_3 (StringLookup)  (None, 1)           0           ['Zone[0][0]']                   \n",
      "                                                                                                  \n",
      " string_lookup_4 (StringLookup)  (None, 1)           0           ['Cluster[0][0]']                \n",
      "                                                                                                  \n",
      " string_lookup_5 (StringLookup)  (None, 1)           0           ['Reference proxy[0][0]']        \n",
      "                                                                                                  \n",
      " string_lookup_6 (StringLookup)  (None, 1)           0           ['Division proxy[0][0]']         \n",
      "                                                                                                  \n",
      " string_lookup_7 (StringLookup)  (None, 1)           0           ['Customer Persona proxy[0][0]'] \n",
      "                                                                                                  \n",
      " integer_lookup (IntegerLookup)  (None, 1)           0           ['index[0][0]']                  \n",
      "                                                                                                  \n",
      " integer_lookup_1 (IntegerLooku  (None, 1)           0           ['id_product[0][0]']             \n",
      " p)                                                                                               \n",
      "                                                                                                  \n",
      " integer_lookup_2 (IntegerLooku  (None, 1)           0           ['Year[0][0]']                   \n",
      " p)                                                                                               \n",
      "                                                                                                  \n",
      " integer_lookup_3 (IntegerLooku  (None, 1)           0           ['Trisem[0][0]']                 \n",
      " p)                                                                                               \n",
      "                                                                                                  \n",
      " normalization (Normalization)  (None, 1)            3           ['Month 1[0][0]']                \n",
      "                                                                                                  \n",
      " normalization_1 (Normalization  (None, 1)           3           ['Month 2[0][0]']                \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " normalization_2 (Normalization  (None, 1)           3           ['LogPerf[0][0]']                \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " normalization_3 (Normalization  (None, 1)           3           ['GHP.new[0][0]']                \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " normalization_4 (Normalization  (None, 1)           3           ['GDP (current US$)[0][0]']      \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " normalization_5 (Normalization  (None, 1)           3           ['GSCPI[0][0]']                  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " normalization_6 (Normalization  (None, 1)           3           ['GIB.new[0][0]']                \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " normalization_7 (Normalization  (None, 1)           3           ['Unnamed: 0[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " normalization_8 (Normalization  (None, 1)           3           ['Month 3[0][0]']                \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " normalization_9 (Normalization  (None, 1)           3           ['Imports of goods and services (\n",
      " )                                                               annual % growth)[0][0]']         \n",
      "                                                                                                  \n",
      " normalization_10 (Normalizatio  (None, 1)           3           ['CHA.new[0][0]']                \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " normalization_11 (Normalizatio  (None, 1)           3           ['EmAv[0][0]']                   \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " normalization_12 (Normalizatio  (None, 1)           3           ['Final consumption expenditure (\n",
      " n)                                                              annual % growth)[0][0]']         \n",
      "                                                                                                  \n",
      " category_encoding (CategoryEnc  (None, 5)           0           ['string_lookup[0][0]']          \n",
      " oding)                                                                                           \n",
      "                                                                                                  \n",
      " category_encoding_1 (CategoryE  (None, 5)           0           ['string_lookup_1[0][0]']        \n",
      " ncoding)                                                                                         \n",
      "                                                                                                  \n",
      " category_encoding_2 (CategoryE  (None, 5)           0           ['string_lookup_2[0][0]']        \n",
      " ncoding)                                                                                         \n",
      "                                                                                                  \n",
      " category_encoding_3 (CategoryE  (None, 5)           0           ['string_lookup_3[0][0]']        \n",
      " ncoding)                                                                                         \n",
      "                                                                                                  \n",
      " category_encoding_4 (CategoryE  (None, 5)           0           ['string_lookup_4[0][0]']        \n",
      " ncoding)                                                                                         \n",
      "                                                                                                  \n",
      " category_encoding_5 (CategoryE  (None, 5)           0           ['string_lookup_5[0][0]']        \n",
      " ncoding)                                                                                         \n",
      "                                                                                                  \n",
      " category_encoding_6 (CategoryE  (None, 4)           0           ['string_lookup_6[0][0]']        \n",
      " ncoding)                                                                                         \n",
      "                                                                                                  \n",
      " category_encoding_7 (CategoryE  (None, 5)           0           ['string_lookup_7[0][0]']        \n",
      " ncoding)                                                                                         \n",
      "                                                                                                  \n",
      " category_encoding_8 (CategoryE  (None, 5)           0           ['integer_lookup[0][0]']         \n",
      " ncoding)                                                                                         \n",
      "                                                                                                  \n",
      " category_encoding_9 (CategoryE  (None, 5)           0           ['integer_lookup_1[0][0]']       \n",
      " ncoding)                                                                                         \n",
      "                                                                                                  \n",
      " category_encoding_10 (Category  (None, 5)           0           ['integer_lookup_2[0][0]']       \n",
      " Encoding)                                                                                        \n",
      "                                                                                                  \n",
      " category_encoding_11 (Category  (None, 4)           0           ['integer_lookup_3[0][0]']       \n",
      " Encoding)                                                                                        \n",
      "                                                                                                  \n",
      " concatenate_4 (Concatenate)    (None, 71)           0           ['normalization[0][0]',          \n",
      "                                                                  'normalization_1[0][0]',        \n",
      "                                                                  'normalization_2[0][0]',        \n",
      "                                                                  'normalization_3[0][0]',        \n",
      "                                                                  'normalization_4[0][0]',        \n",
      "                                                                  'normalization_5[0][0]',        \n",
      "                                                                  'normalization_6[0][0]',        \n",
      "                                                                  'normalization_7[0][0]',        \n",
      "                                                                  'normalization_8[0][0]',        \n",
      "                                                                  'normalization_9[0][0]',        \n",
      "                                                                  'normalization_10[0][0]',       \n",
      "                                                                  'normalization_11[0][0]',       \n",
      "                                                                  'normalization_12[0][0]',       \n",
      "                                                                  'category_encoding[0][0]',      \n",
      "                                                                  'category_encoding_1[0][0]',    \n",
      "                                                                  'category_encoding_2[0][0]',    \n",
      "                                                                  'category_encoding_3[0][0]',    \n",
      "                                                                  'category_encoding_4[0][0]',    \n",
      "                                                                  'category_encoding_5[0][0]',    \n",
      "                                                                  'category_encoding_6[0][0]',    \n",
      "                                                                  'category_encoding_7[0][0]',    \n",
      "                                                                  'category_encoding_8[0][0]',    \n",
      "                                                                  'category_encoding_9[0][0]',    \n",
      "                                                                  'category_encoding_10[0][0]',   \n",
      "                                                                  'category_encoding_11[0][0]']   \n",
      "                                                                                                  \n",
      " dense_24 (Dense)               (None, 32)           2304        ['concatenate_4[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_20 (BatchN  (None, 32)          128         ['dense_24[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_25 (Dense)               (None, 64)           2112        ['batch_normalization_20[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_21 (BatchN  (None, 64)          256         ['dense_25[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_26 (Dense)               (None, 128)          8320        ['batch_normalization_21[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_22 (BatchN  (None, 128)         512         ['dense_26[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_27 (Dense)               (None, 64)           8256        ['batch_normalization_22[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_23 (BatchN  (None, 64)          256         ['dense_27[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_28 (Dense)               (None, 32)           2080        ['batch_normalization_23[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_24 (BatchN  (None, 32)          128         ['dense_28[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_29 (Dense)               (None, 1)            33          ['batch_normalization_24[0][0]'] \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 24,424\n",
      "Trainable params: 23,745\n",
      "Non-trainable params: 679\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "final_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "5eadb04a-f8dd-4c06-b524-db7e37c1e4d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 3288/42605 [=>............................] - ETA: 32:48"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[83], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mfinal_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample_key\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Hackaton/lib/python3.11/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Hackaton/lib/python3.11/site-packages/keras/engine/training.py:2382\u001b[0m, in \u001b[0;36mModel.predict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   2380\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39msteps():\n\u001b[1;32m   2381\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_predict_batch_begin(step)\n\u001b[0;32m-> 2382\u001b[0m     tmp_batch_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2383\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   2384\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/Hackaton/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Hackaton/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:894\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    891\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    893\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 894\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    896\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    897\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/Hackaton/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:933\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    930\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    931\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    932\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 933\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    934\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ALLOW_DYNAMIC_VARIABLE_CREATION:\n\u001b[1;32m    935\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    936\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Hackaton/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:143\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    141\u001b[0m   (concrete_function,\n\u001b[1;32m    142\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 143\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Hackaton/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1757\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1753\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1754\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1755\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1756\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1757\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1758\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1759\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1760\u001b[0m     args,\n\u001b[1;32m   1761\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1762\u001b[0m     executing_eagerly)\n\u001b[1;32m   1763\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/Hackaton/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:381\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    380\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 381\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    384\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    385\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    387\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    388\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    389\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    390\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    393\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    394\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/Hackaton/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "final_model.predict(sample_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ff8895d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 297ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[60], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m sample \u001b[38;5;241m=\u001b[39m X_train[numerical_cols \u001b[38;5;241m+\u001b[39m categorical_cols_string \u001b[38;5;241m+\u001b[39m categorical_cols_int]\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mto_dict()\n\u001b[1;32m      3\u001b[0m input_dict \u001b[38;5;241m=\u001b[39m {name: tf\u001b[38;5;241m.\u001b[39mconvert_to_tensor([value]) \u001b[38;5;28;01mfor\u001b[39;00m name, value \u001b[38;5;129;01min\u001b[39;00m sample\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[0;32m----> 4\u001b[0m final_predictions\u001b[38;5;241m.\u001b[39mappend(\u001b[43mfinal_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_dict\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/Hackaton/lib/python3.11/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Hackaton/lib/python3.11/site-packages/keras/engine/training.py:2349\u001b[0m, in \u001b[0;36mModel.predict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   2340\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[1;32m   2341\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   2342\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing Model.predict with MultiWorkerMirroredStrategy \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2343\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor TPUStrategy and AutoShardPolicy.FILE might lead to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2346\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m   2347\u001b[0m         )\n\u001b[0;32m-> 2349\u001b[0m data_handler \u001b[38;5;241m=\u001b[39m \u001b[43mdata_adapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_data_handler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2352\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2353\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2354\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2355\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2356\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2357\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2358\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2359\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_execution\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_steps_per_execution\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2360\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2362\u001b[0m \u001b[38;5;66;03m# Container that configures and calls `tf.keras.Callback`s.\u001b[39;00m\n\u001b[1;32m   2363\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(callbacks, callbacks_module\u001b[38;5;241m.\u001b[39mCallbackList):\n",
      "File \u001b[0;32m~/Hackaton/lib/python3.11/site-packages/keras/engine/data_adapter.py:1583\u001b[0m, in \u001b[0;36mget_data_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1581\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_cluster_coordinator\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1582\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _ClusterCoordinatorDataHandler(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m-> 1583\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataHandler\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Hackaton/lib/python3.11/site-packages/keras/engine/data_adapter.py:1260\u001b[0m, in \u001b[0;36mDataHandler.__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution, distribute)\u001b[0m\n\u001b[1;32m   1257\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_steps_per_execution \u001b[38;5;241m=\u001b[39m steps_per_execution\n\u001b[1;32m   1259\u001b[0m adapter_cls \u001b[38;5;241m=\u001b[39m select_data_adapter(x, y)\n\u001b[0;32m-> 1260\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_adapter \u001b[38;5;241m=\u001b[39m \u001b[43madapter_cls\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1261\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1262\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1263\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1264\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1265\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1266\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1270\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdistribution_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistribute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_strategy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1273\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1275\u001b[0m strategy \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mget_strategy()\n\u001b[1;32m   1277\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m~/Hackaton/lib/python3.11/site-packages/keras/engine/data_adapter.py:348\u001b[0m, in \u001b[0;36mTensorLikeDataAdapter.__init__\u001b[0;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m flat_dataset\n\u001b[1;32m    346\u001b[0m indices_dataset \u001b[38;5;241m=\u001b[39m indices_dataset\u001b[38;5;241m.\u001b[39mflat_map(slice_batch_indices)\n\u001b[0;32m--> 348\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mslice_inputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindices_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m shuffle \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    352\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mshuffle_batch\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch):\n",
      "File \u001b[0;32m~/Hackaton/lib/python3.11/site-packages/keras/engine/data_adapter.py:400\u001b[0m, in \u001b[0;36mTensorLikeDataAdapter.slice_inputs\u001b[0;34m(self, indices_dataset, inputs)\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shuffle:\n\u001b[1;32m    396\u001b[0m     \u001b[38;5;66;03m# See b/141490660 for more details.\u001b[39;00m\n\u001b[1;32m    397\u001b[0m     options\u001b[38;5;241m.\u001b[39mexperimental_external_state_policy \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    398\u001b[0m         tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mExternalStatePolicy\u001b[38;5;241m.\u001b[39mIGNORE\n\u001b[1;32m    399\u001b[0m     )\n\u001b[0;32m--> 400\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwith_options\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dataset\n",
      "File \u001b[0;32m~/Hackaton/lib/python3.11/site-packages/tensorflow/python/data/ops/dataset_ops.py:2942\u001b[0m, in \u001b[0;36mDatasetV2.with_options\u001b[0;34m(self, options, name)\u001b[0m\n\u001b[1;32m   2916\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwith_options\u001b[39m(\u001b[38;5;28mself\u001b[39m, options, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   2917\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Returns a new `tf.data.Dataset` with the given options set.\u001b[39;00m\n\u001b[1;32m   2918\u001b[0m \n\u001b[1;32m   2919\u001b[0m \u001b[38;5;124;03m  The options are \"global\" in the sense they apply to the entire dataset.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2940\u001b[0m \u001b[38;5;124;03m    ValueError: when an option is set more than once to a non-default value\u001b[39;00m\n\u001b[1;32m   2941\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2942\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_OptionsDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Hackaton/lib/python3.11/site-packages/tensorflow/python/data/ops/dataset_ops.py:4737\u001b[0m, in \u001b[0;36m_OptionsDataset.__init__\u001b[0;34m(self, input_dataset, options, name)\u001b[0m\n\u001b[1;32m   4735\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_dataset \u001b[38;5;241m=\u001b[39m input_dataset\n\u001b[1;32m   4736\u001b[0m options_pb \u001b[38;5;241m=\u001b[39m dataset_options_pb2\u001b[38;5;241m.\u001b[39mOptions()\n\u001b[0;32m-> 4737\u001b[0m options_pb\u001b[38;5;241m.\u001b[39mCopyFrom(\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_to_proto\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   4738\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name \u001b[38;5;241m=\u001b[39m name\n\u001b[1;32m   4739\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mcolocate_with(input_dataset\u001b[38;5;241m.\u001b[39m_variant_tensor):\n",
      "File \u001b[0;32m~/Hackaton/lib/python3.11/site-packages/tensorflow/python/data/ops/options.py:627\u001b[0m, in \u001b[0;36mOptions._to_proto\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdeterministic \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    626\u001b[0m   pb\u001b[38;5;241m.\u001b[39mdeterministic \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdeterministic\n\u001b[0;32m--> 627\u001b[0m pb\u001b[38;5;241m.\u001b[39mautotune_options\u001b[38;5;241m.\u001b[39mCopyFrom(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mautotune\u001b[38;5;241m.\u001b[39m_to_proto())  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    628\u001b[0m pb\u001b[38;5;241m.\u001b[39mdistribute_options\u001b[38;5;241m.\u001b[39mCopyFrom(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_distribute\u001b[38;5;241m.\u001b[39m_to_proto())  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    629\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_external_state_policy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(len(X_train)):\n",
    "    sample = X_train[numerical_cols + categorical_cols_string + categorical_cols_int].iloc[1].to_dict()\n",
    "    input_dict = {name: tf.convert_to_tensor([value]) for name, value in sample.items()}\n",
    "    final_predictions.append(final_model.predict(input_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "db6543c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1363338"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32cd073e-b0f3-4709-8956-f2af3e09e7e7",
   "metadata": {},
   "source": [
    "##### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
